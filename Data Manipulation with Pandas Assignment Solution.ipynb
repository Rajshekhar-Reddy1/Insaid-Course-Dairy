{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Data Manipulation with Pandas Assignment Solution.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOaA9OQ0o0GHluVmdVK0h7U"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"taGKQPOOs81M"},"source":["<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"100\" /></center>"]},{"cell_type":"markdown","metadata":{"id":"-QcwVsIPs-iA"},"source":["**<center><h3>Data Manipulation with Pandas Assignment Solution</h3></center>**"]},{"cell_type":"code","metadata":{"id":"tXu1qu6_s4CU","executionInfo":{"status":"ok","timestamp":1615961341792,"user_tz":-330,"elapsed":1070,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["import numpy as np\r\n","import pandas as pd"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6fsAZAv4tCaL"},"source":["---\r\n","**<h4>Question 1:** Create a function that converts the each letter of first word in a series to uppercase.</h4>\r\n","\r\n","- For example, you passed the series in left column and return the values as shown in right column:\r\n","\r\n","|Original Series|Transformed Series\r\n","|:--|:--|\r\n","|how|How|\r\n","|to|To|\r\n","|learn|Learn|\r\n","|data science?|Data science?|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- You can achieve this question in many ways.\r\n","\r\n","- One way is to perform mapping over the series and using the capitalize functionality of python.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"PkYiizHutCET","executionInfo":{"status":"ok","timestamp":1615961348610,"user_tz":-330,"elapsed":1984,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def upperSeries(series=None):\r\n","  \"\"\"Converts the each letter of first word in a series to uppercase.\"\"\"\r\n","\r\n","  # Performing mapping over the series elements\r\n","  series = series.map(lambda x: x.capitalize())\r\n","  \r\n","  return series"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"iIjUQLyjtCBh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615961349726,"user_tz":-330,"elapsed":3091,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"305a9d5b-84f1-4dfe-ef95-e542be63890f"},"source":["upperSeries(series=pd.Series(['how', 'to', 'learn', 'data science?']))"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0              How\n","1               To\n","2            Learn\n","3    Data science?\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"itQQNwGYtJpu"},"source":["---\r\n","**<h4>Question 2:** Create a function that takes dictionary as input and returns the rows of dataframe containing null data.</h4>\r\n","\r\n","- For example, you passed the dictionary and dataframe looks like as shown below:\r\n","\r\n","|#|Animal|Age|Visits|Priority|\r\n","|:--|:--|:--|:--|:--|\r\n","|01|dog|NaN|3|yes|\r\n","|02|dog|5|2|no|\r\n","|03|cat|2|3|no|\r\n","|04|snake|4|1|no|\r\n","|05|cat|NaN|1|yes|\r\n","\r\n","- The output data will be as shown below:\r\n","\r\n","|#|Animal|Age|Visits|Priority|\r\n","|:--|:--|:--|:--|:--|\r\n","|01|dog|NaN|3|yes|\r\n","|05|cat|NaN|1|yes|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Pass the dictionary containing data to the function.\r\n","\r\n","- Create a dataframe using the pandas DataFrame functionality.\r\n","\r\n","- Filter the data rows containing null data using isnull() and any() method.\r\n","\r\n","- You can also try out some condition inside the dataframe index brackets.\r\n","\r\n","- Return the filtered data back.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"9UyRfboGtB-N","executionInfo":{"status":"ok","timestamp":1615961349734,"user_tz":-330,"elapsed":3089,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def showNanRows(data_dict=None):\r\n","  \"\"\"Returns the data rows containing null data.\"\"\"\r\n","\r\n","  # Create a dataframe out of the data dictionary passed\r\n","  data_frame = pd.DataFrame(data=data_dict)\r\n","\r\n","  # Filter the data rows containing null data\r\n","  data_frame = data_frame[data_frame.isnull().any(axis=1)]\r\n","\r\n","  return data_frame"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"f15GQ5NhtB7i","colab":{"base_uri":"https://localhost:8080/","height":111},"executionInfo":{"status":"ok","timestamp":1615961349741,"user_tz":-330,"elapsed":3082,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"a73cf588-d3ab-49a9-f74c-cedf526db232"},"source":["data_dict = {'Animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\r\n","             'Age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3], \r\n","             'Visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\r\n","             'Priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\r\n","\r\n","showNanRows(data_dict=data_dict)"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Animal</th>\n","      <th>Age</th>\n","      <th>Visits</th>\n","      <th>Priority</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>dog</td>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>yes</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>cat</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  Animal  Age  Visits Priority\n","3    dog  NaN       3      yes\n","7    cat  NaN       1      yes"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"XaKehKcmtVjZ"},"source":["---\r\n","**<h4>Question 3:** Create a function that takes dictionary as input and returns the dataframe of grouped mean of a certain column.</h4>\r\n","\r\n","- For example, you passed the dictionary and dataframe looks like as shown below:\r\n","\r\n","|#|Animal|Age|Visits|Priority|\r\n","|:--|:--|:--|:--|:--|\r\n","|01|dog|NaN|3|yes|\r\n","|02|dog|5|2|no|\r\n","|03|cat|2|3|no|\r\n","|04|snake|4|1|no|\r\n","|05|cat|NaN|1|yes|\r\n","\r\n","- The output data that has been grouped by Animal of mean Age will be as shown below:\r\n","\r\n","|#|Animal|Age|\r\n","|:--|:--|:--|\r\n","|01|cat|2|\r\n","|02|dog|5|\r\n","|03|snake|4|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Pass the dictionary containing data to the function.\r\n","\r\n","- Create a dataframe using the pandas DataFrame functionality.\r\n","\r\n","- Groupby data using pandas package according to the specified groupbycol value.\r\n","\r\n","- Extract columns only specified in returncollist parameter.\r\n","\r\n","- Return the output data.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"aJhCqQI-tB5K","executionInfo":{"status":"ok","timestamp":1615961349742,"user_tz":-330,"elapsed":3078,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def showGroupByMean(data_dict=None, groupbycol=None, returncollist=None):\r\n","  \"\"\"Returns the dataframe of grouped mean of animal column.\"\"\"\r\n","\r\n","  # Create a dataframe out of the data dictionary passed\r\n","  data_frame = pd.DataFrame(data=data_dict)\r\n","\r\n","  # Groupby data with the specified groupby column and columns to return in output\r\n","  grouped_mean = data_frame.groupby(groupbycol)[returncollist].mean()\r\n","\r\n","  return grouped_mean"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"izUAwXyotB2M","colab":{"base_uri":"https://localhost:8080/","height":173},"executionInfo":{"status":"ok","timestamp":1615961349746,"user_tz":-330,"elapsed":3076,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"ea4130e1-e257-404f-f480-94d4907b8bf4"},"source":["data_dict = {'Animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\r\n","             'Age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3], \r\n","             'Visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\r\n","             'Priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\r\n","\r\n","showGroupByMean(data_dict=data_dict, groupbycol='Animal', returncollist=['Age'])"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","    </tr>\n","    <tr>\n","      <th>Animal</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>cat</th>\n","      <td>2.5</td>\n","    </tr>\n","    <tr>\n","      <th>dog</th>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>snake</th>\n","      <td>2.5</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Age\n","Animal     \n","cat     2.5\n","dog     5.0\n","snake   2.5"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"EUtUm8yctcP7"},"source":["---\r\n","**<h4>Question 4:** Create a function that returns the indexes of the dataframe if values matched at a certain index.</h4>\r\n","\r\n","- **Note:** You can create two columns with random values or labels within a certain range.\r\n","\r\n","- For example, you initialized dataframe columns with random values as shown below:\r\n","\r\n","|#|Fruit 1|Fruit 2|\r\n","|:--|:--|:--|\r\n","|01|Banana|Orange|\r\n","|02|Apple|Orange|\r\n","|03|Apple|Apple|\r\n","|04|Orange|Orange|\r\n","|05|Banana|Apple|\r\n","\r\n","- The returned output will be `[3, 4]`.\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Pass a list of items that will be used to create a dataframe of specified data rows.\r\n","\r\n","- To achieve this objective you can use numpy's random choice functionality.\r\n","\r\n","- Next, you can use numpy's where() method to extract out the indexes of data rows containing same values.\r\n","\r\n","- Return the extracted indexes.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"RHbutXANtBzd","executionInfo":{"status":"ok","timestamp":1615961349749,"user_tz":-330,"elapsed":3073,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def checkIndex(itemlist=None, datasize=None):\r\n","  \"\"\"Returns indexes of data rows where both values are same.\"\"\"\r\n","\r\n","  # Create a dataframe with two columns having value in certain range of list.\r\n","  df = pd.DataFrame(data = {'Column 1': np.random.choice(a=itemlist, size=datasize),\r\n","                            'Column 2': np.random.choice(a=itemlist, size=datasize)})\r\n","  \r\n","  # Extract out the indexes where data values match\r\n","  index = np.where(df['Column 1'] == df['Column 2'])\r\n","\r\n","  # Display the output\r\n","  return index"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"tvZKKyZDtBw6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615961349751,"user_tz":-330,"elapsed":3071,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"ea878420-b37f-4cf0-c5dc-c6fc10e932d8"},"source":["checkIndex(itemlist=['apple', 'orange', 'banana'], datasize=10)"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([0, 3, 9]),)"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"rK5vFZU1tneA"},"source":["---\r\n","**<h4>Question 5:** Create a function that returns the indexes of the series if values present are multiple of a certain value.</h4>\r\n","\r\n","- For example, you created a random series of integer as shown below:\r\n","\r\n","|#|Series|\r\n","|:--:|:--:|\r\n","|01|8|\r\n","|02|9|\r\n","|03|8|\r\n","|04|1|\r\n","|05|8|\r\n","\r\n","- The value to be checked as the multiple of values present in the series is `4`.\r\n","\r\n","- The returned output will be `[1, 3, 5]`.\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Pass a list of items that will be used to create a dataframe of specified data rows.\r\n","\r\n","- To achieve this objective you can use numpy's random choice functionality.\r\n","\r\n","- Next, you can use numpy's where() method to extract out the indexes of data rows containing same values.\r\n","\r\n","- Return the extracted indexes.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"oa4ujqMBtnQH","executionInfo":{"status":"ok","timestamp":1615961349758,"user_tz":-330,"elapsed":3071,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def checkMultiple(multiple=None, randstart=None, randstop=None, totalrecords=None):\r\n","  \"\"\"Returns the indexes of the series if values present are multiple of a certain value.\"\"\"\r\n","\r\n","  # Generate random integers according to the specifed parameters\r\n","  data = np.random.randint(low=randstart, high=randstop, size=totalrecords)\r\n","\r\n","  # Create a pandas series of random integers with specified values in function\r\n","  series = pd.Series(data=data)\r\n","\r\n","  # Extract the index position where series value is multiple of passed value\r\n","  pos = np.where(series%multiple == 0)\r\n","\r\n","  return pos"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"m06rsD3StnM-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615961349761,"user_tz":-330,"elapsed":3069,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"0527ca92-bd84-4e6d-8455-32c7fc5a76b6"},"source":["checkMultiple(multiple=4, randstart=1, randstop=10, totalrecords=10)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([3, 4, 5, 6, 8]),)"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"pQeaQbg7twFb"},"source":["---\r\n","**<h4>Question 6:** Create a function that takes two series and stacks them in either horizontal way or vertical way.</h4>\r\n","\r\n","- For example you entered following two series:\r\n","\r\n","|Series 1|\r\n","|:--:|\r\n","|0|\r\n","|1|\r\n","|2|\r\n","|3|\r\n","|4|\r\n","|5|\r\n","\r\n","|Series 2|\r\n","|:--:|\r\n","|I|\r\n","|N|\r\n","|S|\r\n","|A|\r\n","|I|\r\n","|D|\r\n","\r\n","- The returned output will be as shown below if the option selected is horizontal:\r\n","\r\n","|Series 1|Series 2|\r\n","|:--:|:--:|\r\n","|0|I|\r\n","|1|N|\r\n","|2|S|\r\n","|3|A|\r\n","|4|I|\r\n","|5|D|\r\n","\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Use conditional opertaion to check the passed option of stacking the list.\r\n","\r\n","- If the option is horizontal, then perform concatenation of series along axis 1.\r\n","\r\n","- If the option is verticle, then perform appending of series.\r\n","\r\n","- Return the final result.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"CPwPdCeBtnKH","executionInfo":{"status":"ok","timestamp":1615961349762,"user_tz":-330,"elapsed":3067,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def stackSeries(series1=None, series2=None, stack='verticle'):\r\n","  \"\"\"Return series stacked in horizontal way.\"\"\"\r\n","\r\n","  # Check if option selected is horizontal or not\r\n","  if stack == 'horizontal':\r\n","    return pd.concat([series1, series2], axis=1)\r\n","\r\n","  return series1.append(series2)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZA774cbAtnHB","colab":{"base_uri":"https://localhost:8080/","height":235},"executionInfo":{"status":"ok","timestamp":1615961349764,"user_tz":-330,"elapsed":3064,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"b2723d6d-1b85-4153-e22c-e5aba5f23cd0"},"source":["s1 = pd.Series(range(6))\r\n","s2 = pd.Series(list('INSAID'))\r\n","\r\n","stackSeries(series1=s1, series2=s2, stack='horizontal')"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>I</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>N</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>A</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>D</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0  1\n","0  0  I\n","1  1  N\n","2  2  S\n","3  3  A\n","4  4  I\n","5  5  D"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"Vj7lmBznufhB"},"source":["---\r\n","**<h4>Question 7:** Create a function that performs min-max scaling over the numerical columns of the data.</h4>\r\n","\r\n","- **Dataset link:** 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\r\n","\r\n","- For example, you have a column where values are `[4.9, 4.7, 4.6, 5.0, 5.4]`.\r\n","\r\n","- After performing min-max scaling the values will become `[0.22, 0.16, 0.11, 0.08, 0.19]`.\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Read the data from the specified link and provide columns names if not present already.\r\n","\r\n","- You can use pandas read_csv functionality and its constituent parameters.\r\n","\r\n","- Extract and append numerical column names out of the dataset using control flow & string operations.\r\n","\r\n","- Again start a new control flow operation and extract minimum and maximum value of each column.\r\n","\r\n","- Use apply() method and lambda operation over each column to perform min-max scaling.\r\n","\r\n","- The formula of min-max scaling is: $\\large\\frac {value - min}{max - min}$\r\n","\r\n","- One way is to perform mapping over the series and using the capitalize functionality of python.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"5kET0VfgtnER","executionInfo":{"status":"ok","timestamp":1615961349765,"user_tz":-330,"elapsed":3062,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def minMaxScaling(link=None, datacolnames=None):\r\n","  \"\"\"Performs min-max scaling over the numerical features.\"\"\"\r\n","\r\n","  # Read the data from the specified link and column names if not present already\r\n","  data = pd.read_csv(filepath_or_buffer=link, names=datacolnames)\r\n","\r\n","  # Extract the numerical features\r\n","  numfeatures = []\r\n","  for i in data.columns:\r\n","    if (data[i].dtype == float) | (data[i].dtype == int):\r\n","      numfeatures.append(i)\r\n","\r\n","  # Iterate scaling over each numerical column\r\n","  for i in numfeatures:\r\n","\r\n","    # Get minimum value of the column\r\n","    feat_min = data[i].min()\r\n","\r\n","    # Get maximum value of the column\r\n","    feat_max = data[i].max()\r\n","\r\n","    # Perform min-max scaling over each numerical column\r\n","    data[i] = data[i].apply(lambda x: (x - feat_min) / (feat_max - feat_min))\r\n","  \r\n","  return data"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"B0Ay0A9_tnBv","colab":{"base_uri":"https://localhost:8080/","height":419},"executionInfo":{"status":"ok","timestamp":1615961349766,"user_tz":-330,"elapsed":3060,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"ec24ec9a-8783-45bd-8dc1-89fb10742199"},"source":["url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\r\n","names=['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\r\n","\r\n","minMaxScaling(link=url, datacolnames=names)"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length</th>\n","      <th>sepal width</th>\n","      <th>petal length</th>\n","      <th>petal width</th>\n","      <th>class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.222222</td>\n","      <td>0.625000</td>\n","      <td>0.067797</td>\n","      <td>0.041667</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.166667</td>\n","      <td>0.416667</td>\n","      <td>0.067797</td>\n","      <td>0.041667</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.111111</td>\n","      <td>0.500000</td>\n","      <td>0.050847</td>\n","      <td>0.041667</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.083333</td>\n","      <td>0.458333</td>\n","      <td>0.084746</td>\n","      <td>0.041667</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.194444</td>\n","      <td>0.666667</td>\n","      <td>0.067797</td>\n","      <td>0.041667</td>\n","      <td>Iris-setosa</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>0.666667</td>\n","      <td>0.416667</td>\n","      <td>0.711864</td>\n","      <td>0.916667</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>0.555556</td>\n","      <td>0.208333</td>\n","      <td>0.677966</td>\n","      <td>0.750000</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>0.611111</td>\n","      <td>0.416667</td>\n","      <td>0.711864</td>\n","      <td>0.791667</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>0.527778</td>\n","      <td>0.583333</td>\n","      <td>0.745763</td>\n","      <td>0.916667</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>0.444444</td>\n","      <td>0.416667</td>\n","      <td>0.694915</td>\n","      <td>0.708333</td>\n","      <td>Iris-virginica</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>150 rows × 5 columns</p>\n","</div>"],"text/plain":["     sepal length  sepal width  petal length  petal width           class\n","0        0.222222     0.625000      0.067797     0.041667     Iris-setosa\n","1        0.166667     0.416667      0.067797     0.041667     Iris-setosa\n","2        0.111111     0.500000      0.050847     0.041667     Iris-setosa\n","3        0.083333     0.458333      0.084746     0.041667     Iris-setosa\n","4        0.194444     0.666667      0.067797     0.041667     Iris-setosa\n","..            ...          ...           ...          ...             ...\n","145      0.666667     0.416667      0.711864     0.916667  Iris-virginica\n","146      0.555556     0.208333      0.677966     0.750000  Iris-virginica\n","147      0.611111     0.416667      0.711864     0.791667  Iris-virginica\n","148      0.527778     0.583333      0.745763     0.916667  Iris-virginica\n","149      0.444444     0.416667      0.694915     0.708333  Iris-virginica\n","\n","[150 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"markdown","metadata":{"id":"KhiNeJNAul4T"},"source":["---\r\n","**<h4>Question 8:** Create a function that returns the index positions of the missing data value and its total in a specific column.</h4>\r\n","\r\n","- **Dataset link:** 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\r\n","\r\n","- For example, you have a column where values are `[4.9, 4.7, 4.6, 5.0, 5.4]`.\r\n","\r\n","- After performing min-max scaling the values will become `[0.22, 0.16, 0.11, 0.08, 0.19]`.\r\n","  \r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Read the data from the specified link and provide columns names if not present already.\r\n","\r\n","- You can use pandas read_csv functionality and its constituent parameters.\r\n","\r\n","- Calculate total missing values in a specified column using pandas isnull() and sum() method.\r\n","\r\n","- Similarly, you can use numpy's where() method in addtion to the isnull() method to get the index positions of missing data.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"AlSOdK5oulfT","executionInfo":{"status":"ok","timestamp":1615961349767,"user_tz":-330,"elapsed":3055,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def showMissingIndex(link=None, datacolnames=None, checkcol=None):\r\n","  \"\"\"Returns index positions of missing data row of a specific column.\"\"\"\r\n","\r\n","  # Read the data from the specified link and column names if not present already\r\n","  data = pd.read_csv(filepath_or_buffer=link, names=datacolnames)\r\n","\r\n","  # Display total missing values in a specified column\r\n","  print('Total Missing:', data[checkcol].isnull().sum())\r\n","  \r\n","  # Display the index positions of missing data row\r\n","  print('Indexes:', np.where(data[checkcol].isnull()))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"4yaaAgtmulba","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615961350395,"user_tz":-330,"elapsed":3680,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"a157ec96-72cf-42be-e413-bfd88b22f2cc"},"source":["url = 'https://raw.githubusercontent.com/insaid2018/Domain_Case_Studies/master/Healthcare/Heart%20Disease%20Diagnosis/Data/heart_disease.csv'\r\n","\r\n","showMissingIndex(link=url, checkcol='cholesterol')"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Total Missing: 18\n","Indexes: (array([ 38,  45,  46,  55, 125, 162, 164, 179, 199, 204, 221, 232, 237,\n","       249, 284, 303, 314, 328]),)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"x-4kA5lkuyey"},"source":["---\r\n","**<h4>Question 9:** Create a function that replace missing values with the mean value of the column, if present.</h4>\r\n","\r\n","- For example, you have a following dataset:\r\n","\r\n","|#|age|sex|chest_pain_type|resting_blood_pressure|cholesterol|fasting_blood_sugar|rest_ecg|target|\r\n","|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\r\n","|01|63|1|asymptomatic\t|145|233.0|1|1|1|\r\n","|02|37|0|non-anginal pain|140|245.0|0|1|0|\r\n","|03|41|1|typical anginia\t|135|NaN|1|1|0|\r\n","|04|48|0|asymptomatic\t|110|274|0|0|0|\r\n","|05|66|1|non-anginal pain|130|288|1|1|1|\r\n","\r\n","- The cholesterol column contains one missing value and mean of this column is `262.25`.\r\n","\r\n","- The final dataframe will look something like as follows:\r\n","\r\n","|#|age|sex|chest_pain_type|resting_blood_pressure|cholesterol|fasting_blood_sugar|rest_ecg|target|\r\n","|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\r\n","|01|63|1|asymptomatic\t|145|233.0|1|1|1|\r\n","|02|37|0|non-anginal pain|140|245.0|0|1|0|\r\n","|03|41|1|typical anginia\t|135|262.25|1|1|0|\r\n","|04|48|0|asymptomatic\t|110|274|0|0|0|\r\n","|05|66|1|non-anginal pain|130|288|1|1|1|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Read the data from the specified link and provide column names if not present already.\r\n","\r\n","- You can use pandas read_csv functionality and its constituent parameters.\r\n","\r\n","- Check if the data column contains missing data using pandas isnull() and any() method.\r\n","\r\n","- If column contains missing data then replace the missing data cell using .replace() method.\r\n","\r\n","- After replacing the missing data values in the column again check if there exists missing data.\r\n","\r\n","- If no missing data in the column then return the final data.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"TohtOV27ulXX","executionInfo":{"status":"ok","timestamp":1615961350397,"user_tz":-330,"elapsed":3679,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def replaceMissingMean(link=url, datacolnames=None, colname=None):\r\n","  \"\"\"Imputes missing data value with mean value of the column.\"\"\"\r\n","\r\n","  # Read the data from the specified link and column names if not present already\r\n","  data = pd.read_csv(filepath_or_buffer=link, names=datacolnames)\r\n","\r\n","  # Display if originally column contains missing values \r\n","  print('Before Replacing, Contains Missing?:', data[colname].isnull().any())\r\n","\r\n","  # Replace missing data value\r\n","  data[colname] = data[colname].replace(to_replace=np.nan, value=data[colname].mean())\r\n","\r\n","  # Display if after replacing column contains missing values \r\n","  print('After Replacing, Contains Missing?:', data[colname].isnull().any())\r\n","\r\n","  return data"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2g2c_DFulTU","colab":{"base_uri":"https://localhost:8080/","height":473},"executionInfo":{"status":"ok","timestamp":1615961350399,"user_tz":-330,"elapsed":3678,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"d372f104-0030-48ae-c0d2-830fff4be951"},"source":["url = 'https://raw.githubusercontent.com/insaid2018/Domain_Case_Studies/master/Healthcare/Heart%20Disease%20Diagnosis/Data/heart_disease.csv'\r\n","\r\n","replaceMissingMean(link=url, datacolnames=None, colname='cholesterol')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Before Replacing, Contains Missing?: True\n","After Replacing, Contains Missing?: False\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>chest_pain_type</th>\n","      <th>resting_blood_pressure</th>\n","      <th>cholesterol</th>\n","      <th>fasting_blood_sugar</th>\n","      <th>rest_ecg</th>\n","      <th>max_heart_rate_achieved</th>\n","      <th>exercise_induced_angina</th>\n","      <th>st_depression</th>\n","      <th>st_slope</th>\n","      <th>num_major_vessels</th>\n","      <th>thalassemia</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>63</td>\n","      <td>1</td>\n","      <td>asymptomatic</td>\n","      <td>145</td>\n","      <td>233.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>150.0</td>\n","      <td>0</td>\n","      <td>2.3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>37</td>\n","      <td>1</td>\n","      <td>non-anginal pain</td>\n","      <td>130</td>\n","      <td>250.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>187.0</td>\n","      <td>0</td>\n","      <td>3.5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>atypical angina</td>\n","      <td>130</td>\n","      <td>204.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>172.0</td>\n","      <td>0</td>\n","      <td>1.4</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>56</td>\n","      <td>1</td>\n","      <td>atypical angina</td>\n","      <td>120</td>\n","      <td>236.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>178.0</td>\n","      <td>0</td>\n","      <td>0.8</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>57</td>\n","      <td>0</td>\n","      <td>typical anginia</td>\n","      <td>120</td>\n","      <td>354.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>163.0</td>\n","      <td>1</td>\n","      <td>0.6</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>361</th>\n","      <td>45</td>\n","      <td>1</td>\n","      <td>asymptomatic</td>\n","      <td>110</td>\n","      <td>264.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>132.0</td>\n","      <td>0</td>\n","      <td>1.2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>362</th>\n","      <td>48</td>\n","      <td>1</td>\n","      <td>typical angina</td>\n","      <td>124</td>\n","      <td>274.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>166.0</td>\n","      <td>0</td>\n","      <td>0.5</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>363</th>\n","      <td>66</td>\n","      <td>1</td>\n","      <td>typical angina</td>\n","      <td>160</td>\n","      <td>228.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>2.3</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>364</th>\n","      <td>34</td>\n","      <td>1</td>\n","      <td>asymptomatic</td>\n","      <td>118</td>\n","      <td>182.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>0.0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>365</th>\n","      <td>51</td>\n","      <td>1</td>\n","      <td>typical angina</td>\n","      <td>140</td>\n","      <td>298.0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>122.0</td>\n","      <td>1</td>\n","      <td>4.2</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>366 rows × 14 columns</p>\n","</div>"],"text/plain":["     age  sex   chest_pain_type  ...  num_major_vessels  thalassemia  target\n","0     63    1      asymptomatic  ...                  0            1       1\n","1     37    1  non-anginal pain  ...                  0            2       1\n","2     41    0   atypical angina  ...                  0            2       1\n","3     56    1   atypical angina  ...                  0            2       1\n","4     57    0   typical anginia  ...                  0            2       1\n","..   ...  ...               ...  ...                ...          ...     ...\n","361   45    1      asymptomatic  ...                  0            3       0\n","362   48    1    typical angina  ...                  0            3       0\n","363   66    1    typical angina  ...                  0            1       1\n","364   34    1      asymptomatic  ...                  0            2       1\n","365   51    1    typical angina  ...                  3            3       0\n","\n","[366 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"q00uuRnSu8os"},"source":["---\r\n","**<h4>Question 10:** Create a function that generates random numbers ranging from Date A to Date B.</h4>\r\n","\r\n","- For example, you passed `start_date = \"2016-01-01\"` and `end_date = \"2016-12-31\"`.\r\n","\r\n","- The frequency used will be `freq = \"B\"` Here \"B\" refers to the business day frequency.\r\n","\r\n","- The output data will be as shown below:\r\n","\r\n","|Date|Value|\r\n","|:--:|:--:|\r\n","|2016-01-01|0.095|\r\n","|2016-01-02|0.340|\r\n","|2016-01-03|0.253|\r\n","|2016-01-04|0.254|\r\n","|2016-01-05|0.243|\r\n","||...|\r\n","|2016-12-30|0.664|\r\n","|2016-12-31|0.343|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Take help from pandas date_range functionality.\r\n","\r\n","- Set all the parameters according to the function requirement.\r\n","\r\n","- Generate data of length equal to the date length.\r\n","\r\n","- Create a pandas series out of the random data and date and return it.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"D3BZh0GAu5g2","executionInfo":{"status":"ok","timestamp":1615961350402,"user_tz":-330,"elapsed":3677,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def randDateData(start_date=None, end_date=None, freq=None):\r\n","  \"\"\"Generate random values ranging from Date A to Date B.\"\"\"\r\n","\r\n","  # Generates date ranging from specified value in the function\r\n","  date = pd.date_range(start=start_date, end=end_date, freq=freq)\r\n","\r\n","  # Generate random data ranging from Date A to Date B\r\n","  data = np.random.rand(len(date))\r\n","\r\n","  # Create series of random values from the generated date\r\n","  rand_date_val = pd.Series(data=data, index=date)\r\n","\r\n","  return rand_date_val"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"BaKs0sNOulQD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615961350405,"user_tz":-330,"elapsed":3677,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"f8e8d6b2-c23e-4477-f080-9fe50ec018fb"},"source":["randDateData(start_date='2016-01-01', end_date='2016-12-31', freq=\"B\")"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2016-01-01    0.139002\n","2016-01-04    0.278280\n","2016-01-05    0.539974\n","2016-01-06    0.315909\n","2016-01-07    0.335295\n","                ...   \n","2016-12-26    0.108642\n","2016-12-27    0.218235\n","2016-12-28    0.531132\n","2016-12-29    0.672738\n","2016-12-30    0.520354\n","Freq: B, Length: 261, dtype: float64"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"uLQWkDrsvGZS"},"source":["---\r\n","**<h4>Question 11:** Create a function that performs one hot encoding over the data column.</h4>\r\n","\r\n","- For example, you passed the dictionary or read the data and dataframe looks like as shown below:\r\n","\r\n","|#|Animal|Age|Visits|Priority|\r\n","|:--:|:--:|:--:|:--:|:--:|\r\n","|01|dog|NaN|3|yes|\r\n","|02|dog|5|2|no|\r\n","|03|cat|2|3|no|\r\n","|04|snake|4|1|no|\r\n","|05|cat|NaN|1|yes|\r\n","\r\n","- You column selected for one hot encoding is Animal.\r\n","\r\n","- The returned data will look like as follow:\r\n","\r\n","|#|Age|Visits|Priority|Animal_cat|Animal_dog|Animal_snake|\r\n","|:--:|:--:|:--:|:--:|:--:|:--:|:--:|\r\n","|01|NaN|3|yes|0|1|0|\r\n","|02|5|2|no|0|1|0|\r\n","|03|2|3|no|1|0|0|\r\n","|04|4|1|no|0|0|1|\r\n","|05|NaN|1|yes|1|0|0|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- There are many ways to accomplish this question.\r\n","\r\n","- Either you can use a library or use pandas functionality of get_dummies() method.\r\n","\r\n","- You can also add a condition in the function to identify the type of data and take actions accordingly.\r\n","\r\n","- To know more about the one hot encoding click <a href=\"https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/\">**here**</a>.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"RgT-pwC9ulM_","executionInfo":{"status":"ok","timestamp":1615961350407,"user_tz":-330,"elapsed":3676,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def oneHotEncode(data=None, cols=None):\r\n","  \"\"\"Performs one hot encoding over the specified data column.\"\"\"\r\n","\r\n","  # Check if the data type is pandas dataframe\r\n","  if type(data) == 'pandas.core.frame.DataFrame':\r\n","\r\n","    # Return the one hot encoded data column\r\n","    return pd.get_dummies(data=data, columns=cols)\r\n","\r\n","  # Creates dataframe out of dictionary if data type is not dataframe\r\n","  data = pd.DataFrame(data=data)\r\n","\r\n","  return pd.get_dummies(data=data, columns=cols)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"HF91_LCPulJF","colab":{"base_uri":"https://localhost:8080/","height":359},"executionInfo":{"status":"ok","timestamp":1615961350409,"user_tz":-330,"elapsed":3675,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"7682809b-63bb-4a57-d9f7-b89fe435158c"},"source":["data_dict = {'Animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],\r\n","             'Age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3], \r\n","             'Visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\r\n","             'Priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}\r\n","\r\n","oneHotEncode(data=data_dict, cols=['Animal'])"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Age</th>\n","      <th>Visits</th>\n","      <th>Priority</th>\n","      <th>Animal_cat</th>\n","      <th>Animal_dog</th>\n","      <th>Animal_snake</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>2.5</td>\n","      <td>1</td>\n","      <td>yes</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>3.0</td>\n","      <td>3</td>\n","      <td>yes</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.5</td>\n","      <td>2</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>NaN</td>\n","      <td>3</td>\n","      <td>yes</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>2</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>2.0</td>\n","      <td>3</td>\n","      <td>no</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>4.5</td>\n","      <td>1</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>yes</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>7.0</td>\n","      <td>2</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3.0</td>\n","      <td>1</td>\n","      <td>no</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Age  Visits Priority  Animal_cat  Animal_dog  Animal_snake\n","0  2.5       1      yes           1           0             0\n","1  3.0       3      yes           1           0             0\n","2  0.5       2       no           0           0             1\n","3  NaN       3      yes           0           1             0\n","4  5.0       2       no           0           1             0\n","5  2.0       3       no           1           0             0\n","6  4.5       1       no           0           0             1\n","7  NaN       1      yes           1           0             0\n","8  7.0       2       no           0           1             0\n","9  3.0       1       no           0           1             0"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"YPOlNvK8vRlI"},"source":["---\r\n","**<h4>Question 12:** Create a function that removes duplicates (if present) and subtract the filtered data with the mean of the column.</h4>\r\n","\r\n","- For example you have the following data:\r\n","\r\n","|Column data|\r\n","|:--:|\r\n","|1|\r\n","|2|\r\n","|2|\r\n","|3|\r\n","|4|\r\n","|5|\r\n","|5|\r\n","|5|\r\n","|6|\r\n","|7|\r\n","\r\n","- The filtered data will be:\r\n","\r\n","|Column data|\r\n","|:--:|\r\n","|1|\r\n","|2|\r\n","|3|\r\n","|4|\r\n","|5|\r\n","|6|\r\n","|7|\r\n","\r\n","- Let's say the mean of the column is \"4\", then the final series will be:\r\n","\r\n","|Column data|\r\n","|:--:|\r\n","|-3|\r\n","|-2|\r\n","|-1|\r\n","|0|\r\n","|1|\r\n","|2|\r\n","|3|\r\n","\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Check if the passed data is a dataframe or not.\r\n","\r\n","- If dataframe, then drop the duplicates using the drop_duplicates() functionality of pandas.\r\n","\r\n","- Then subtract the output with the mean of the column and return it.\r\n","\r\n","- If the type of data is dictionary, then typecast it to the pandas dataframe first.\r\n","\r\n","- Drop the duplicates using the drop_duplicates() functionality of pandas.\r\n","\r\n","- Then subtract the output with the mean of the column and return it.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"nWmoKWWHulFh","executionInfo":{"status":"ok","timestamp":1615961350411,"user_tz":-330,"elapsed":3674,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def filterData(data=None, names=None):\r\n","  \"\"\"Remove duplicates (if present) and subtract the filtered data with the mean of the column.\"\"\"\r\n","  \r\n","  # Check if the data type is pandas dataframe\r\n","  if type(data) == 'pandas.core.frame.DataFrame':\r\n","\r\n","    # Drop duplicates\r\n","    data.drop_duplicates(inplace=True)\r\n","\r\n","    # Return the subtracted values\r\n","    return data.sub(other=data.mean(axis=0), axis=1)\r\n","\r\n","  # Creates dataframe out of dictionary if data type is not dataframe\r\n","  data = pd.DataFrame(data=data, columns=names)\r\n","\r\n","  # Drop duplicates\r\n","  data.drop_duplicates(inplace=True)\r\n","\r\n","  # Return the subtracted values\r\n","  return data.sub(other=data.mean(axis=0), axis=1)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"8TAW7P2kulCG","colab":{"base_uri":"https://localhost:8080/","height":266},"executionInfo":{"status":"ok","timestamp":1615961350412,"user_tz":-330,"elapsed":3672,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"a5cb436d-6ecc-4f2b-f461-add9453582af"},"source":["data = {'Column data': [1, 2, 2, 3, 4, 5, 5, 5, 6, 7, 7]}\r\n","filterData(data=data, names=None)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Column data</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-3.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-2.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-1.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Column data\n","0         -3.0\n","1         -2.0\n","3         -1.0\n","4          0.0\n","5          1.0\n","8          2.0\n","9          3.0"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"HeZqvWPiws1v"},"source":["---\r\n","**<h4>Question 13:** Create a function that performs dataframe merging over the specified column name.</h4>\r\n","\r\n","- For example,\r\n","\r\n","<center><img src=\"https://pandas.pydata.org/pandas-docs/stable/_images/merging_merge_on_key_multiple.png\"></center>\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Check if the passed data are of type DataFrame.\r\n","\r\n","- If yes, then merge data 1 and data 2 over the specified column name.\r\n","\r\n","- To achive the merging, you can use pandas's merge() functionality.\r\n","\r\n","- Next, if the data is of type dictionary, then typecast the data to DataFrame.\r\n","\r\n","- Then merge data 1 and data 2 over the specified column name using merge() method.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"FkBs1nmzuk-j","executionInfo":{"status":"ok","timestamp":1615961350414,"user_tz":-330,"elapsed":3671,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def dataframeMerge(data1=None, data2=None, key=None):\r\n","  \"\"\"Perform dataframe merging over the specified column name.\"\"\"\r\n","\r\n","  # Check if the data is of type DataFrame\r\n","  if (type(data1) == 'pandas.core.frame.DataFrame') & (type(data2) == 'pandas.core.frame.DataFrame'):\r\n","\r\n","    # Return the merged data over the specified column name\r\n","    return pd.merge(left=data1, right=data2, on=key)\r\n","\r\n","  # Typecast dictionary to dataframe\r\n","  data1 = pd.DataFrame(data=data1)\r\n","  data2 = pd.DataFrame(data=data2)\r\n","\r\n","  # Return the merged data over the specified column name\r\n","  return pd.merge(left=data1, right=data2, on=key)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dq5qWNNjuk7M","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1615961350415,"user_tz":-330,"elapsed":3669,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"a938c395-a12a-4c93-b052-ffae527a613b"},"source":["d1 = pd.DataFrame({\"key1\": [\"K0\", \"K0\", \"K1\", \"K2\"], \"key2\": [\"K0\", \"K1\", \"K0\", \"K1\"],\r\n","                     \"A\": [\"A0\", \"A1\", \"A2\", \"A3\"], \"B\": [\"B0\", \"B1\", \"B2\", \"B3\"],\r\n","                     })\r\n","\r\n","d2 = pd.DataFrame({\"key1\": [\"K0\", \"K1\", \"K1\", \"K2\"], \"key2\": [\"K0\", \"K0\", \"K0\", \"K0\"],\r\n","                   \"C\": [\"C0\", \"C1\", \"C2\", \"C3\"], \"D\": [\"D0\", \"D1\", \"D2\", \"D3\"],\r\n","                   })\r\n","\r\n","dataframeMerge(data1=d1, data2=d2, key=[\"key1\", \"key2\"])"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>key1</th>\n","      <th>key2</th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>D</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>K0</td>\n","      <td>K0</td>\n","      <td>A0</td>\n","      <td>B0</td>\n","      <td>C0</td>\n","      <td>D0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>K1</td>\n","      <td>K0</td>\n","      <td>A2</td>\n","      <td>B2</td>\n","      <td>C1</td>\n","      <td>D1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>K1</td>\n","      <td>K0</td>\n","      <td>A2</td>\n","      <td>B2</td>\n","      <td>C2</td>\n","      <td>D2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  key1 key2   A   B   C   D\n","0   K0   K0  A0  B0  C0  D0\n","1   K1   K0  A2  B2  C1  D1\n","2   K1   K0  A2  B2  C2  D2"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"jjwevaUow0lH"},"source":["---\r\n","**<h4>Question 14:** Create a function that returns all rows of a DataFrame containing a given substring.</h4>\r\n","\r\n","- For example, you passed 9 random values such as:\r\n","  -  `[0.83086063, 0.00536904, 0.58981977, 0.76704028, 0.55501003, 0.91354796, 0.57879962, 0.76508311, 0.66402454]`.\r\n","\r\n","- The value returned will be:\r\n","    - `|0.83086063 0.00536904 0.58981977|`\r\n","    - `|0.76704028 0.55501003 0.91354796|`\r\n","    - `|0.57879962 0.76508311 0.66402454|`\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Check if the type of data passed is of type DataFrame or not.\r\n","\r\n","- If yes, then return the dataframe with filtered values containing substring in a specific column.\r\n","\r\n","- You can use .str() along with the contains() method to filter out the data.\r\n","\r\n","- If data is of type dictionary, then typecast it to DataFrame first.\r\n","\r\n","- Then filter dataframe rows containing substring in a specific column.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"FXFOdo-Ww0Wv","executionInfo":{"status":"ok","timestamp":1615961350417,"user_tz":-330,"elapsed":3668,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def filterOnSubstring(data=None, colname=None, substring=None):\r\n","  \"\"\"Filters dataframe containing a given substring.\"\"\"\r\n","\r\n","  # Check if the data is of type DataFrame\r\n","  if type(data) == 'pandas.core.frame.DataFrame':\r\n","\r\n","    # Returns dataframe containing a specified substring\r\n","    return data[data[colname].str.contains(substring)]\r\n","\r\n","  # Typecast to dataframe\r\n","  data = pd.DataFrame(data=data)\r\n","  \r\n","  # Returns dataframe containing a specified substring\r\n","  return data[data[colname].str.contains(substring)]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"fiCa0nR3uk4A","colab":{"base_uri":"https://localhost:8080/","height":142},"executionInfo":{"status":"ok","timestamp":1615961350420,"user_tz":-330,"elapsed":3668,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"f9fc0a17-648b-4f3f-d8ac-6f140b358ccc"},"source":["data = pd.DataFrame({'Name': ['Mukesh', 'Mohit', 'Hemanka', 'Abhigyan', 'Ashish'], \r\n","                   'Team': ['Research', 'Research', 'Research', 'Research', 'Research'], \r\n","                   'Position': ['Senior', 'Senior', 'Junior', 'Junior', 'Junior'], \r\n","                   'Age': [24, 25, 23, 24, 24], \r\n","                   'College': ['DAV University', np.nan, np.nan, np.nan, 'Lovely University'], \r\n","                   'Salary': [30000, 30000, 50000, 10000, 10000]})\r\n","\r\n","filterOnSubstring(data=data, colname='Position', substring='Junior')"],"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Name</th>\n","      <th>Team</th>\n","      <th>Position</th>\n","      <th>Age</th>\n","      <th>College</th>\n","      <th>Salary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2</th>\n","      <td>Hemanka</td>\n","      <td>Research</td>\n","      <td>Junior</td>\n","      <td>23</td>\n","      <td>NaN</td>\n","      <td>50000</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Abhigyan</td>\n","      <td>Research</td>\n","      <td>Junior</td>\n","      <td>24</td>\n","      <td>NaN</td>\n","      <td>10000</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Ashish</td>\n","      <td>Research</td>\n","      <td>Junior</td>\n","      <td>24</td>\n","      <td>Lovely University</td>\n","      <td>10000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Name      Team Position  Age            College  Salary\n","2   Hemanka  Research   Junior   23                NaN   50000\n","3  Abhigyan  Research   Junior   24                NaN   10000\n","4    Ashish  Research   Junior   24  Lovely University   10000"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"EzGAsHR7w9_o"},"source":["---\r\n","**<h4>Question 15:** Create a function that replaces values in a pandas dataframe using a regex.</h4>\r\n","\r\n","- **Note:** If you don't know what is regular expression or regex, then click <a href=\"https://www.w3schools.com/python/python_regex.asp#:~:text=A%20RegEx%2C%20or%20Regular%20Expression,contains%20the%20specified%20search%20pattern.\">**here**</a> to get more information.\r\n","\r\n","- For example, you passed the dataframe that looks like as shown below:\r\n","\r\n","|#|City|Event|Cost|\r\n","|:--:|:--:|:--:|:--:|\r\n","|01|New York|Music|10000|\r\n","|02|Parague|Poetry|5000|\r\n","|03|New Delhi|Theatre|15000|\r\n","|04|Venice|Comedy|2000|\r\n","|05|New Orleans|Tech Summit|12000|\r\n","\r\n","- The output data will be as shown below:\r\n","\r\n","|#|City|Event|Cost|\r\n","|:--:|:--:|:--:|:--:|\r\n","|01|New_York|Music|10000|\r\n","|02|Parague|Poetry|5000|\r\n","|03|New_Delhi|Theatre|15000|\r\n","|04|Venice|Comedy|2000|\r\n","|05|New_Orleans|Tech Summit|12000|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Check if the data passed is of type DataFrame or not.\r\n","\r\n","- If yes, then replace the dataframe values with the specified parameters.\r\n","\r\n","- The regex value will be specified in \"to_replace\" and the \"value\" to be replaced with.\r\n","\r\n","- You can use .replace() functionality to accomplish this tasks.\r\n","\r\n","- Next, if the type of data is not of type DataFrame, then typecast it to a DataFrame first.\r\n","\r\n","- Then return the data with replaced value using .replace() method by specifying the regex.\r\n","\r\n","</details>"]},{"cell_type":"markdown","metadata":{"id":"PSsyofWCxHsK"},"source":["---\r\n","**<h4>Question 16:** Create a function that stacks or unstack the data present in a dataframe.</h4>\r\n","\r\n","- For example, you passed the dataframe that looks like as shown below:\r\n","\r\n","|#|City|Event|Cost|\r\n","|:--:|:--:|:--:|:--:|\r\n","|0|New York|Music|10000|\r\n","|1|Parague|Poetry|5000|\r\n","|2|New Delhi|Theatre|15000|\r\n","|3|Venice|Comedy|2000|\r\n","|4|New Orleans|Tech Summit|12000|\r\n","\r\n","- The condition passed is \"stack\" and the output data will be returned as shown below:\r\n","\r\n","|#|Feature|Value|\r\n","|:--:|:--:|:--:|\r\n","|0|City|New York|\r\n","|0|Event|Music|\r\n","|0|Cost|10000|\r\n","|1|City|Parague|\r\n","|1|Event|Poetry|\r\n","|1|Cost|5000|\r\n","|2|City|New Delhi|\r\n","|2|Event|Theatre|\r\n","|2|Cost|15000|\r\n","|3|City|Venice|\r\n","|3|Event|Comedy|\r\n","|3|Cost|2000|\r\n","|4|City|New Orleans|\r\n","|4|Event|Tech Summit|\r\n","|4|Cost|12000|\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Check if the data passed is of type DataFrame or not.\r\n","\r\n","- If yes, then check if the passed condition is \"unstack\".\r\n","\r\n","- If yes, then return the unstacked version of data using .unstack() method.\r\n","\r\n","- Else return the stacked version of data using .stack() method.\r\n","\r\n","- Next, if the data is not of type DataFrame, then typecast the passed data to a DataFrame.\r\n","\r\n","- Check if the passed condition is \"unstack\".\r\n","\r\n","- If yes, then return the unstacked version of data using .unstack() method.\r\n","\r\n","- Else return the stacked version of data using .stack() method.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"z5Q8zhOLuk06","executionInfo":{"status":"ok","timestamp":1615961350927,"user_tz":-330,"elapsed":4171,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def stackOrUnstack(data=None, condition=None):\r\n","  \"\"\"Returns a stacked or unstacked format of data in a dataframe.\"\"\"\r\n","\r\n","  # Check if the data is of type DataFrame\r\n","  if type(data) == 'pandas.core.frame.DataFrame':\r\n","    \r\n","    # Check if the condition is of type unstack\r\n","    if condition == 'unstack':\r\n","      return data.unstack()\r\n","\r\n","    # Stack the data if the above condition fails to execute\r\n","    else:\r\n","      return data.stack()\r\n","  \r\n","  # Typecast the data to pandas dataframe\r\n","  data = pd.DataFrame(data=data)\r\n","\r\n","  # Check if the condition is of type unstack\r\n","  if condition == 'unstack':\r\n","    return data.unstack()\r\n","    \r\n","  # Stack the data if the above condition fails to execute\r\n","  return data.stack() "],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"0BLcQPiUukx4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615961350929,"user_tz":-330,"elapsed":4168,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"70d25cea-c5e6-492f-d27c-3157bece43a2"},"source":["df = pd.DataFrame({'City':['New York', 'Parague', 'New Delhi', 'Venice', 'new Orleans'], \r\n","                   'Event':['Music', 'Poetry', 'Theatre', 'Comedy', 'Tech Summit'], \r\n","                   'Cost':[10000, 5000, 15000, 2000, 12000]})\r\n","\r\n","stackOrUnstack(data=df, condition='stack')"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0  City        New York\n","   Event          Music\n","   Cost           10000\n","1  City         Parague\n","   Event         Poetry\n","   Cost            5000\n","2  City       New Delhi\n","   Event        Theatre\n","   Cost           15000\n","3  City          Venice\n","   Event         Comedy\n","   Cost            2000\n","4  City     new Orleans\n","   Event    Tech Summit\n","   Cost           12000\n","dtype: object"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"jbRZ0SgixQmH"},"source":["---\r\n","**<h4>Question 17:** Create a function that returns a list of pandas dataframe.</h4>\r\n","\r\n","- For example, you passed the dataframe that looks like as shown below:\r\n","\r\n","|#|City|Event|Cost|\r\n","|:--:|:--:|:--:|:--:|\r\n","|0|New York|Music|10000|\r\n","|1|Parague|Poetry|5000|\r\n","|2|New Delhi|Theatre|15000|\r\n","|3|Venice|Comedy|2000|\r\n","|4|New Orleans|Tech Summit|12000|\r\n","\r\n","- The returned output will be as shown below:\r\n","\r\n","<center>[['New York', 'Music', 10000],</center>\r\n","<center>['Parague', 'Poetry', 5000],</center>\r\n","<center>['New Delhi', 'Theatre', 15000],</center>\r\n","<center>['Venice', 'Comedy', 2000],</center>\r\n","<center>['new Orleans', 'Tech Summit', 12000]]</center>\r\n","\r\n","<details>\r\n","\r\n","**<summary>Hint:</summary>**\r\n","\r\n","- Check if the data passed is of type DataFrame or not.\r\n","\r\n","- If yes, then iterate over the rows using .iterrows() functionality of pandas.\r\n","\r\n","- Using conditional looping extract the index and rows of dataframe.\r\n","\r\n","- Next, you need to use list comprehension to extract each value of a record to a list and return it back.\r\n","\r\n","- If the passed data is of type other than DataFrame, then typecast it to a dataframe first.\r\n","\r\n","- Initialize an empty list and, then iterate over the rows using .iterrows() functionality of pandas.\r\n","\r\n","- Using conditional looping extract the index and rows of dataframe.\r\n","\r\n","- Next, use a list comprehension to extract each value of a record to a list and append it to the initialized list.\r\n","\r\n","- Return the appended list and display the output.\r\n","\r\n","</details>"]},{"cell_type":"code","metadata":{"id":"v_fjqMXJukuF","executionInfo":{"status":"ok","timestamp":1615961350942,"user_tz":-330,"elapsed":4178,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}}},"source":["def listFromDataFrame(data=None):\r\n","  \"\"\"Returns a list of rows from the pandas dataframe.\"\"\"\r\n","\r\n","  # Check if the data is of type DataFrame\r\n","  if type(data) == 'pandas.core.frame.DataFrame':\r\n","    \r\n","    # Retrieve index and rows of pandas dataframe\r\n","    for index, rows in data.iterrows():\r\n","\r\n","      # Extract each value of cell of each row to a list\r\n","      row_list = [rows[i] for i in data.columns]\r\n","\r\n","      # Return the row as a list\r\n","      return row_list\r\n","  \r\n","  # Typecast the data to a pandas dataframe\r\n","  data = pd.DataFrame(data=data)\r\n","\r\n","  # Initiate an empty list\r\n","  row_list = []\r\n","\r\n","  # Retrieve index and rows of pandas dataframe\r\n","  for index, rows in data.iterrows():\r\n","\r\n","    # Extract each value of cell of each row to a list\r\n","    temp_list = [rows[i] for i in data.columns]\r\n","\r\n","    # Append the temporary list of rows to the initialized list\r\n","    row_list.append(temp_list)\r\n","\r\n","  # Return rows as a list\r\n","  return row_list"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"cy4ll-cftBkO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615961350949,"user_tz":-330,"elapsed":4182,"user":{"displayName":"Mukesh Kumar","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjTZH-ccUwdv--s75Iw1qfyi7gtUyH2m_-htD2e=s64","userId":"01238672520445611335"}},"outputId":"f115da0b-73c0-4fe8-b50b-398454432c03"},"source":["df = pd.DataFrame({'City':['New York', 'Parague', 'New Delhi', 'Venice', 'new Orleans'], \r\n","                   'Event':['Music', 'Poetry', 'Theatre', 'Comedy', 'Tech Summit'], \r\n","                   'Cost':[10000, 5000, 15000, 2000, 12000]})\r\n","\r\n","listFromDataFrame(data=df)"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['New York', 'Music', 10000],\n"," ['Parague', 'Poetry', 5000],\n"," ['New Delhi', 'Theatre', 15000],\n"," ['Venice', 'Comedy', 2000],\n"," ['new Orleans', 'Tech Summit', 12000]]"]},"metadata":{"tags":[]},"execution_count":33}]}]}